{"cells":[{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1707900576686,"user":{"displayName":"Navami Sunil Rajagiri","userId":"01137070985807425093"},"user_tz":-330},"id":"LpOkk-3jQO94"},"outputs":[],"source":["# importing libraries\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()\n","import json\n","import pickle\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Dropout\n","from keras.optimizers import SGD\n","import random\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":502,"status":"ok","timestamp":1707900604570,"user":{"displayName":"Navami Sunil Rajagiri","userId":"01137070985807425093"},"user_tz":-330},"id":"TwiLep0xRCkT","outputId":"f6554ec6-5eb8-4b0f-d8fc-f29b026f9ca6"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["import nltk\n","import json\n","import pickle\n","\n","\n","\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","\n","from nltk.stem import WordNetLemmatizer\n","\n","\n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":529,"status":"ok","timestamp":1707900643654,"user":{"displayName":"Navami Sunil Rajagiri","userId":"01137070985807425093"},"user_tz":-330},"id":"CUWab5DiQnLC","outputId":"c355ca57-a9f1-4758-e934-695f4c6dd9c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["283 documents\n","129 classes ['What are the types of depression?', 'about', 'afternoon', 'anxious', 'ask', 'at what age does anxiety peak?', 'can lack of sleep make you feel sad?', 'can low blood sugar cause suicidal thoughts?', 'casual', 'creation', 'death', 'default', 'depressed', 'do we control our thoughts?', 'does oversleeping cause depression?', 'done', 'evening', 'fact-1', 'fact-10', 'fact-11', 'fact-12', 'fact-13', 'fact-14', 'fact-15', 'fact-16', 'fact-17', 'fact-18', 'fact-19', 'fact-2', 'fact-20', 'fact-21', 'fact-22', 'fact-23', 'fact-24', 'fact-25', 'fact-26', 'fact-27', 'fact-28', 'fact-29', 'fact-3', 'fact-30', 'fact-31', 'fact-32', 'fact-5', 'fact-6', 'fact-7', 'fact-8', 'fact-9', 'friends', 'goodbye', 'greeting', 'happy', 'hate-me', 'hate-you', 'help', 'how can we reduce anxiety?', 'how does depression affect the world?', 'how long can anxiety last?', 'how many thoughts a day do we have?', 'i am a victim of bullying', 'i am afraid i will fail again', 'i am afraid to file a case against bullying', 'i am feeling anxious lately.', 'i am feeling stressed lately', 'i am good for nothing!', 'i am good for nothing.', 'i am lonely!', 'i am sad', 'i am stressed out', \"i can't do this anymore\", 'i feel i have let my parents down', 'i hate losing.', 'i hate myself!', 'i let everyojokne down', 'i think i am ugly!', \"i think i'm losing my mind\", 'i want a break', 'i want to kill myself', 'i want to leave the cou ntry and run away', 'i will never succeed in life', \"i wish i could've been a winner\", 'i wish i was better than them', 'i wish to quit', 'is depression a side effect of diabetes?', 'is school a cause of depression?', 'jamila-useful', 'jokes', 'learn-mental-health', 'learn-more', 'location', 'meditation', 'mental-health-fact', 'morning', 'my time has come', 'neutral-response', 'night', 'no one likes me!', 'no-approach', 'no-response', 'not-talking', 'problem', 'repeat', 'sad', 'scared', 'skill', 'sleep', 'something-else', 'stressed', 'stupid', 'suicide', 'thanks', 'understand', 'user-advice', 'user-agree', 'user-meditation', 'what are the causes of depression?', 'what are the stages of anxiety?', 'what are the top causes of depression?', 'what is depression?', 'what is the 3 3 3 rule for anxiety?', 'what is the biological cause of depression?', 'what is the meaning of anxiety and depression?', 'which age group has the highest rate of depression?', 'which country has the highest rate of depression?', 'which country has the lowest rate of depression?', 'which race has the highest rate of depression?', 'why is anxiety bad for you?', 'worthless', 'wrong']\n","355 unique lemmatized words [\"'ll\", \"'m\", \"'re\", \"'s\", \"'ve\", ',', '.', '3', 'a', 'about', 'absolutely', 'advice', 'affect', 'afraid', 'afternoon', 'again', 'against', 'age', 'all', 'alot', 'already', 'am', 'and', 'another', 'answer', 'anxiety', 'anxious', 'any', 'anymore', 'anyone', 'anything', 'appears', 'approaching', 'are', 'ask', 'at', 'au', 'available', 'away', 'awful', 'bad', 'be', 'because', 'become', 'been', 'before', 'better', 'between', 'biological', 'blood', 'bonjour', 'boyfriend', 'break', 'bring', 'brother', 'bullying', 'burned', 'bye', 'ca', 'call', 'can', 'case', 'cause', 'cheerful', 'child', 'come', 'commit', 'connection', 'continue', 'control', 'cou', 'could', 'country', 'crazy', 'created', 'cure', 'dad', 'day', 'define', 'depressed', 'depression', 'deserve', 'diabetes', 'did', 'die', 'died', 'difference', 'different', 'disorder', 'do', 'doe', 'down', 'dumb', 'effect', 'else', 'empty', 'enough', 'evening', 'everyojokne', 'exam', 'fact', 'fail', 'family', 'fare', 'feel', 'feeling', 'few', 'file', 'financial', 'find', 'fine', 'focus', 'for', 'friend', 'from', 'get', 'girlfriend', 'give', 'go', 'going', 'good', 'goodbye', 'great', 'group', 'guess', 'ha', 'had', 'hand', 'happy', 'hate', 'have', 'hay', 'health', 'hello', 'help', 'helpful', 'hey', 'hi', 'highest', 'hmmm', 'hola', 'how', 'howdy', 'i', 'if', 'ill', 'illness', 'importance', 'important', 'in', 'insominia', 'insomnia', 'interested', 'involved', 'is', 'it', 'joke', 'just', 'k', 'kill', 'killing', 'know', 'lack', 'last', 'lately', 'later', 'learn', 'learning', 'leave', 'let', 'life', 'like', 'live', 'location', 'lonely', 'long', 'losing', 'low', 'lowest', 'made', 'maintain', 'make', 'many', 'me', 'mean', 'meaning', 'medication', 'meditation', 'mental', 'mentally', 'mentioned', 'mind', 'mom', 'money', 'more', 'morning', 'much', 'my', 'myself', \"n't\", 'name', 'need', 'never', 'new', 'nice', 'night', 'no', 'nobody', 'not', 'nothing', 'now', 'ntry', 'of', 'oh', 'ok', 'okay', 'on', 'one', 'open', 'option', 'or', 'our', 'out', 'oversleeping', 'parent', 'passed', 'past', 'peak', 'people', 'please', 'possibly', 'practicing', 'prepared', 'prevent', 'probably', 'problem', 'professional', 'proper', 'quit', 'race', 'rate', 'really', 'recover', 'reduce', 'relationship', 'repeating', 'response', 'revoir', 'right', 'robot', 'rule', 'run', 'sad', 'sadness', 'said', 'sasa', 'say', 'saying', 'sayonara', 'scared', 'school', 'see', 'seem', 'sense', 'should', 'shut', 'side', 'sign', 'sister', 'sleep', 'slept', 'so', 'social', 'some', 'someone', 'something', 'sound', 'stage', 'starting', 'stay', 'still', 'stress', 'stressed', 'stuck', 'stupid', 'succeed', 'suffering', 'sugar', 'suicidal', 'suicide', 'support', 'sure', 'symptom', 'take', 'talk', 'tell', 'than', 'thank', 'thanks', 'that', 'the', 'thee', 'them', 'then', 'therapist', 'therapy', 'there', 'think', 'this', 'thought', 'through', 'time', 'to', 'today', 'told', 'top', 'treatment', 'trust', 'type', 'ugly', 'understand', 'understands', 'unwell', 'up', 'useful', 'useless', 'very', 'victim', 'wa', 'want', 'warning', 'way', 'we', 'well', 'were', 'what', 'whatever', 'where', 'which', 'who', 'why', 'will', 'winner', 'wish', 'with', 'world', 'worried', 'worthless', 'would', 'wrong', 'yeah', 'yes', 'you', 'your', 'yourself']\n"]}],"source":["# tokenizing and lematizing\n","words=[]\n","classes = []\n","documents = []\n","ignore_words = ['?', '!']\n","data_file = open('intents.json').read()\n","intents = json.loads(data_file)\n","\n","for intent in intents['intents']:\n","    for pattern in intent['patterns']:\n","        #tokenize each word\n","        w = nltk.word_tokenize(pattern)\n","        words.extend(w)\n","        #add documents in the corpus\n","        documents.append((w, intent['tag']))\n","        # add to our classes list\n","        if intent['tag'] not in classes:\n","            classes.append(intent['tag'])\n","# lemmatize and lower each word and remove duplicates\n","words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n","#sorts unique lemmatized words\n","words = sorted(list(set(words)))\n","# sort classes\n","classes = sorted(list(set(classes)))\n","# documents = combination between patterns and intents\n","print (len(documents), \"documents\")\n","# classes = intents\n","print (len(classes), \"classes\", classes)\n","# words = all words, vocabulary\n","print (len(words), \"unique lemmatized words\", words)\n","pickle.dump(words,open('texts.pkl','wb'))\n","pickle.dump(classes,open('labels.pkl','wb'))\n","# create our training data\n","training = []\n","# create an empty array for our output\n","output_empty = [0] * len(classes)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":518,"status":"ok","timestamp":1707900649312,"user":{"displayName":"Navami Sunil Rajagiri","userId":"01137070985807425093"},"user_tz":-330},"id":"YRgXPOZ-RmgE"},"outputs":[],"source":["# training set, bag of words for each sentence\n","for doc in documents:\n","    # initialize our bag of words\n","    bag = []\n","    # list of tokenized words for the pattern\n","    pattern_words = doc[0]\n","    # lemmatize each word - create base word, in attempt to represent related words\n","    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n","    # create our bag of words array with 1, if word match found in current pattern\n","    for w in words:\n","        bag.append(1) if w in pattern_words else bag.append(0)\n","\n","    # output is a '0' for each tag and '1' for current tag (for each pattern)\n","    output_row = list(output_empty)\n","    output_row[classes.index(doc[1])] = 1\n","\n","    training.append([bag, output_row])\n"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"elapsed":532,"status":"error","timestamp":1707900705809,"user":{"displayName":"Navami Sunil Rajagiri","userId":"01137070985807425093"},"user_tz":-330},"id":"moOLzRdFRq_S","outputId":"a5d8ad01-058f-45f4-dd87-059c5b9e8466"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training data created\n"]}],"source":["import numpy as np\n","import random\n","random.shuffle(training)\n","training = np.array(training, dtype=\"object\")\n","train_x = list(training[:,0])\n","train_y = list(training[:,1])\n","print(\"Training data created\")\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"lnYK9HzQRu1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n"]}],"source":["# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n","# equal to number of intents to predict output intent with softmax\n","model = Sequential()\n","model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(len(train_y[0]), activation='softmax'))"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"WkMOYGsoSRQK"},"outputs":[],"source":["from tensorflow.keras.optimizers import SGD\n","\n","sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n","model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29211,"status":"ok","timestamp":1707734337631,"user":{"displayName":"Navami Sunil Rajagiri","userId":"01137070985807425093"},"user_tz":-330},"id":"YFTox5AASSUS","outputId":"7526929d-d36a-4322-e01f-c81bd2483de2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/200\n","57/57 [==============================] - 1s 2ms/step - loss: 0.7186 - accuracy: 0.7880\n","Epoch 2/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8150 - accuracy: 0.7562\n","Epoch 3/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7771 - accuracy: 0.8057\n","Epoch 4/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7813 - accuracy: 0.7703\n","Epoch 5/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7478 - accuracy: 0.7809\n","Epoch 6/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6990 - accuracy: 0.7809\n","Epoch 7/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8203 - accuracy: 0.7739\n","Epoch 8/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6320 - accuracy: 0.8339\n","Epoch 9/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7881 - accuracy: 0.7739\n","Epoch 10/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6703 - accuracy: 0.8163\n","Epoch 11/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6493 - accuracy: 0.7986\n","Epoch 12/200\n","57/57 [==============================] - 0s 3ms/step - loss: 0.6955 - accuracy: 0.8021\n","Epoch 13/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.7986\n","Epoch 14/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8942 - accuracy: 0.7420\n","Epoch 15/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.8021\n","Epoch 16/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7566 - accuracy: 0.7739\n","Epoch 17/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6757 - accuracy: 0.7915\n","Epoch 18/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.7809\n","Epoch 19/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7579 - accuracy: 0.7915\n","Epoch 20/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6215 - accuracy: 0.8127\n","Epoch 21/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.5952 - accuracy: 0.7951\n","Epoch 22/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.8092\n","Epoch 23/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.7986\n","Epoch 24/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7154 - accuracy: 0.8092\n","Epoch 25/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.7915\n","Epoch 26/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7693 - accuracy: 0.7633\n","Epoch 27/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6854 - accuracy: 0.7951\n","Epoch 28/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.8057\n","Epoch 29/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7777 - accuracy: 0.7739\n","Epoch 30/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8394 - accuracy: 0.7597\n","Epoch 31/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7023 - accuracy: 0.7739\n","Epoch 32/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7687 - accuracy: 0.7809\n","Epoch 33/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7035 - accuracy: 0.7880\n","Epoch 34/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7692 - accuracy: 0.7703\n","Epoch 35/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.8198\n","Epoch 36/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.7915\n","Epoch 37/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8943 - accuracy: 0.7420\n","Epoch 38/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.8304\n","Epoch 39/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8152 - accuracy: 0.7845\n","Epoch 40/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7882 - accuracy: 0.7562\n","Epoch 41/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.8092\n","Epoch 42/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7660 - accuracy: 0.8127\n","Epoch 43/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.7951\n","Epoch 44/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6399 - accuracy: 0.8198\n","Epoch 45/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6033 - accuracy: 0.8233\n","Epoch 46/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7440 - accuracy: 0.7562\n","Epoch 47/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.7915\n","Epoch 48/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8186 - accuracy: 0.7739\n","Epoch 49/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6664 - accuracy: 0.8198\n","Epoch 50/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7195 - accuracy: 0.7845\n","Epoch 51/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.8127\n","Epoch 52/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6709 - accuracy: 0.8127\n","Epoch 53/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9125 - accuracy: 0.7491\n","Epoch 54/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7970 - accuracy: 0.7527\n","Epoch 55/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.8163\n","Epoch 56/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7142 - accuracy: 0.7703\n","Epoch 57/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7049 - accuracy: 0.7809\n","Epoch 58/200\n","57/57 [==============================] - 0s 3ms/step - loss: 0.7021 - accuracy: 0.7986\n","Epoch 59/200\n","57/57 [==============================] - 0s 3ms/step - loss: 0.7273 - accuracy: 0.7951\n","Epoch 60/200\n","57/57 [==============================] - 0s 3ms/step - loss: 0.7526 - accuracy: 0.7774\n","Epoch 61/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7606 - accuracy: 0.7951\n","Epoch 62/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7589 - accuracy: 0.7597\n","Epoch 63/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7012 - accuracy: 0.7880\n","Epoch 64/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.7986\n","Epoch 65/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7405 - accuracy: 0.7951\n","Epoch 66/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6685 - accuracy: 0.7915\n","Epoch 67/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.8021\n","Epoch 68/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7039 - accuracy: 0.8021\n","Epoch 69/200\n","57/57 [==============================] - 0s 3ms/step - loss: 0.8897 - accuracy: 0.7562\n","Epoch 70/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7980 - accuracy: 0.7703\n","Epoch 71/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7756 - accuracy: 0.7915\n","Epoch 72/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7081 - accuracy: 0.8092\n","Epoch 73/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.8163\n","Epoch 74/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7352 - accuracy: 0.7880\n","Epoch 75/200\n","57/57 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.8127\n","Epoch 76/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7881 - accuracy: 0.7951\n","Epoch 77/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6687 - accuracy: 0.8092\n","Epoch 78/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8028 - accuracy: 0.7774\n","Epoch 79/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8613 - accuracy: 0.7633\n","Epoch 80/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7138 - accuracy: 0.8092\n","Epoch 81/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.8445\n","Epoch 82/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.7986\n","Epoch 83/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.8233\n","Epoch 84/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9745 - accuracy: 0.7350\n","Epoch 85/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7630 - accuracy: 0.8092\n","Epoch 86/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8821 - accuracy: 0.7633\n","Epoch 87/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7199 - accuracy: 0.8021\n","Epoch 88/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6790 - accuracy: 0.8163\n","Epoch 89/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8212 - accuracy: 0.7562\n","Epoch 90/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9477 - accuracy: 0.7774\n","Epoch 91/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8011 - accuracy: 0.7703\n","Epoch 92/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8419 - accuracy: 0.7527\n","Epoch 93/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9432 - accuracy: 0.7562\n","Epoch 94/200\n","57/57 [==============================] - 0s 2ms/step - loss: 1.0182 - accuracy: 0.7350\n","Epoch 95/200\n","57/57 [==============================] - 0s 2ms/step - loss: 1.0480 - accuracy: 0.7067\n","Epoch 96/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7877 - accuracy: 0.7597\n","Epoch 97/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7496 - accuracy: 0.7845\n","Epoch 98/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.8233\n","Epoch 99/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6977 - accuracy: 0.8057\n","Epoch 100/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.7986\n","Epoch 101/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.8092\n","Epoch 102/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.8163\n","Epoch 103/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6594 - accuracy: 0.8269\n","Epoch 104/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8019 - accuracy: 0.7880\n","Epoch 105/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7362 - accuracy: 0.7809\n","Epoch 106/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8443 - accuracy: 0.7527\n","Epoch 107/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6729 - accuracy: 0.7845\n","Epoch 108/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7343 - accuracy: 0.7597\n","Epoch 109/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8082 - accuracy: 0.7915\n","Epoch 110/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7581 - accuracy: 0.8092\n","Epoch 111/200\n","57/57 [==============================] - 0s 3ms/step - loss: 0.7595 - accuracy: 0.7915\n","Epoch 112/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7943 - accuracy: 0.7774\n","Epoch 113/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.8021\n","Epoch 114/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7384 - accuracy: 0.7915\n","Epoch 115/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8628 - accuracy: 0.7845\n","Epoch 116/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8422 - accuracy: 0.7986\n","Epoch 117/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8685 - accuracy: 0.7739\n","Epoch 118/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7130 - accuracy: 0.8233\n","Epoch 119/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8883 - accuracy: 0.7562\n","Epoch 120/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8313 - accuracy: 0.7774\n","Epoch 121/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6392 - accuracy: 0.8163\n","Epoch 122/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.8198\n","Epoch 123/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9523 - accuracy: 0.7633\n","Epoch 124/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6382 - accuracy: 0.8057\n","Epoch 125/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7523 - accuracy: 0.7951\n","Epoch 126/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7801 - accuracy: 0.7491\n","Epoch 127/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8360 - accuracy: 0.7809\n","Epoch 128/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8610 - accuracy: 0.7845\n","Epoch 129/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8350 - accuracy: 0.7809\n","Epoch 130/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7839 - accuracy: 0.7562\n","Epoch 131/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.7986\n","Epoch 132/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7807 - accuracy: 0.8021\n","Epoch 133/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9435 - accuracy: 0.7668\n","Epoch 134/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7933 - accuracy: 0.7880\n","Epoch 135/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9511 - accuracy: 0.7314\n","Epoch 136/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7395 - accuracy: 0.7986\n","Epoch 137/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8295 - accuracy: 0.7597\n","Epoch 138/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7075 - accuracy: 0.7986\n","Epoch 139/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7517 - accuracy: 0.7739\n","Epoch 140/200\n","57/57 [==============================] - 0s 3ms/step - loss: 0.8404 - accuracy: 0.7491\n","Epoch 141/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8674 - accuracy: 0.7951\n","Epoch 142/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8949 - accuracy: 0.7456\n","Epoch 143/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9409 - accuracy: 0.7845\n","Epoch 144/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.8269\n","Epoch 145/200\n","57/57 [==============================] - 0s 2ms/step - loss: 1.0461 - accuracy: 0.7420\n","Epoch 146/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8002 - accuracy: 0.8057\n","Epoch 147/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9954 - accuracy: 0.7208\n","Epoch 148/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9678 - accuracy: 0.7633\n","Epoch 149/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9404 - accuracy: 0.7527\n","Epoch 150/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8092 - accuracy: 0.7951\n","Epoch 151/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7790 - accuracy: 0.7880\n","Epoch 152/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8330 - accuracy: 0.7668\n","Epoch 153/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8181 - accuracy: 0.7597\n","Epoch 154/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7941 - accuracy: 0.7774\n","Epoch 155/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9533 - accuracy: 0.7703\n","Epoch 156/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8620 - accuracy: 0.8092\n","Epoch 157/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8095 - accuracy: 0.7809\n","Epoch 158/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7719 - accuracy: 0.7774\n","Epoch 159/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8834 - accuracy: 0.7774\n","Epoch 160/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8038 - accuracy: 0.7597\n","Epoch 161/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9573 - accuracy: 0.7562\n","Epoch 162/200\n","57/57 [==============================] - 0s 2ms/step - loss: 1.0888 - accuracy: 0.7597\n","Epoch 163/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8585 - accuracy: 0.7420\n","Epoch 164/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9673 - accuracy: 0.6996\n","Epoch 165/200\n","57/57 [==============================] - 0s 2ms/step - loss: 1.0797 - accuracy: 0.6926\n","Epoch 166/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8110 - accuracy: 0.7597\n","Epoch 167/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8586 - accuracy: 0.7774\n","Epoch 168/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7453 - accuracy: 0.8198\n","Epoch 169/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9135 - accuracy: 0.7633\n","Epoch 170/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8213 - accuracy: 0.7986\n","Epoch 171/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8722 - accuracy: 0.7703\n","Epoch 172/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.8304\n","Epoch 173/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9404 - accuracy: 0.7633\n","Epoch 174/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8071 - accuracy: 0.7703\n","Epoch 175/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7690 - accuracy: 0.7809\n","Epoch 176/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8074 - accuracy: 0.7668\n","Epoch 177/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8879 - accuracy: 0.7915\n","Epoch 178/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7894 - accuracy: 0.7951\n","Epoch 179/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7144 - accuracy: 0.7986\n","Epoch 180/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6457 - accuracy: 0.8198\n","Epoch 181/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6212 - accuracy: 0.8198\n","Epoch 182/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8421 - accuracy: 0.7562\n","Epoch 183/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8811 - accuracy: 0.7597\n","Epoch 184/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9600 - accuracy: 0.7420\n","Epoch 185/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8245 - accuracy: 0.7668\n","Epoch 186/200\n","57/57 [==============================] - 0s 2ms/step - loss: 1.1009 - accuracy: 0.6961\n","Epoch 187/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7261 - accuracy: 0.8092\n","Epoch 188/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9990 - accuracy: 0.7527\n","Epoch 189/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9120 - accuracy: 0.7703\n","Epoch 190/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.6711 - accuracy: 0.8163\n","Epoch 191/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9320 - accuracy: 0.7633\n","Epoch 192/200\n","57/57 [==============================] - 0s 3ms/step - loss: 1.0540 - accuracy: 0.7668\n","Epoch 193/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9965 - accuracy: 0.7774\n","Epoch 194/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9231 - accuracy: 0.7562\n","Epoch 195/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.7428 - accuracy: 0.7951\n","Epoch 196/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8100 - accuracy: 0.7562\n","Epoch 197/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8140 - accuracy: 0.7739\n","Epoch 198/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.9860 - accuracy: 0.7420\n","Epoch 199/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8007 - accuracy: 0.7774\n","Epoch 200/200\n","57/57 [==============================] - 0s 2ms/step - loss: 0.8808 - accuracy: 0.7668\n","model created\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}],"source":["\n","\n","#fitting and saving the model\n","hist = model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)\n","model.save('model.h5', hist)\n","print(\"model created\")"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"UISG0x0aV8pW"},"outputs":[],"source":["from transformers import AutoModelForSequenceClassification\n","from transformers import AutoTokenizer"]},{"cell_type":"markdown","metadata":{"id":"vz287DeMKeUQ"},"source":[]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"1i8vQQKbZqzK","outputId":"e1e64b0d-3811-49ff-f996-8ed82bae1e65"},"outputs":[{"name":"stdout","output_type":"stream","text":[" * Serving Flask app '__main__'\n"," * Debug mode: off\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n"," * Running on http://127.0.0.1:5000\n","Press CTRL+C to quit\n","127.0.0.1 - - [23/Feb/2024 16:14:21] \"GET /static/styles/ui1.css HTTP/1.1\" 304 -\n","127.0.0.1 - - [23/Feb/2024 16:14:21] \"GET /static/styles/Mental-health-Chatbot-master/static/img/ui.jpg HTTP/1.1\" 404 -\n","127.0.0.1 - - [23/Feb/2024 16:14:24] \"GET /static/img/pic.png HTTP/1.1\" 304 -\n","127.0.0.1 - - [23/Feb/2024 16:15:08] \"GET / HTTP/1.1\" 200 -\n","127.0.0.1 - - [23/Feb/2024 16:15:08] \"GET /static/styles/ui1.css HTTP/1.1\" 200 -\n","127.0.0.1 - - [23/Feb/2024 16:15:09] \"GET /static/styles/Mental-health-Chatbot-master/static/img/ui.jpg HTTP/1.1\" 404 -\n","127.0.0.1 - - [23/Feb/2024 16:15:12] \"GET /static/img/pic.png HTTP/1.1\" 304 -\n","127.0.0.1 - - [23/Feb/2024 16:15:28] \"GET / HTTP/1.1\" 200 -\n","127.0.0.1 - - [23/Feb/2024 16:15:28] \"GET /static/styles/ui1.css HTTP/1.1\" 200 -\n","127.0.0.1 - - [23/Feb/2024 16:15:28] \"GET /static/styles/Mental-health-Chatbot-master/static/img/ui.jpg HTTP/1.1\" 404 -\n","127.0.0.1 - - [23/Feb/2024 16:15:31] \"GET /static/img/pic.png HTTP/1.1\" 304 -\n"]}],"source":["import random\n","import json\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","import numpy as np\n","from flask import Flask, render_template, request\n","from tensorflow.keras.models import load_model\n","\n","lemmatizer = WordNetLemmatizer()\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","\n","intents = json.loads(open('intents.json').read())\n","words = pickle.load(open('texts.pkl','rb'))\n","classes = pickle.load(open('labels.pkl','rb'))\n","model = load_model('model.h5')\n","\n","def clean_up_sentence(sentence):\n","    sentence_words = nltk.word_tokenize(sentence)\n","    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n","    return sentence_words\n","\n","def bow(sentence, words, show_details=True):\n","    sentence_words = clean_up_sentence(sentence)\n","    bag = [0]*len(words)\n","    for s in sentence_words:\n","        for i,w in enumerate(words):\n","            if w == s:\n","                bag[i] = 1\n","                if show_details:\n","                    print (\"found in bag: %s\" % w)\n","    return(np.array(bag))\n","\n","def predict_class(sentence, model):\n","    p = bow(sentence, words,show_details=False)\n","    res = model.predict(np.array([p]))[0]\n","    ERROR_THRESHOLD = 0.25\n","    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n","    results.sort(key=lambda x: x[1], reverse=True)\n","    return_list = []\n","    for r in results:\n","        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n","    return return_list\n","\n","def getResponse(ints, intents_json):\n","    if ints:\n","        tag = ints[0]['intent']\n","        list_of_intents = intents_json['intents']\n","        for i in list_of_intents:\n","            if i['tag'] == tag:\n","                result = random.choice(i['responses'])\n","                break\n","        return result\n","    else:\n","        return \"Sorry, I didn't understand that.\"\n","\n","def chatbot_response(msg):\n","    ints = predict_class(msg, model)\n","    res = getResponse(ints, intents)\n","    print(res)\n","    return res\n","\n","# app = Flask(__name__,template_folder=r'C:\\Users\\HP\\Downloads\\Mental-health-Chatbot-master\\Mental-health-Chatbot-master\\templates')\n","app = Flask(__name__, template_folder='C:\\\\Users\\\\HP\\\\Downloads\\\\Mental-health-Chatbot-master\\\\Mental-health-Chatbot-master\\\\templates')\n","\n","app.static_folder = 'C:\\\\Users\\\\HP\\\\Downloads\\\\Mental-health-Chatbot-master\\\\Mental-health-Chatbot-master\\\\static'\n","\n","\n","@app.route(\"/\")\n","def home():\n","    return render_template(\"ui1.html\")\n","\n","@app.route(\"/bot\")\n","def bot():\n","    return render_template(\"index.html\")\n","\n","@app.route(\"/get\")\n","def get_bot_response():\n","    userText = request.args.get('msg')\n","    print(userText)\n","    response = chatbot_response(userText)\n","    print(response)\n","    return response\n","\n","if __name__ == \"__main__\":\n","    app.run()"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":64,"status":"ok","timestamp":1707734004021,"user":{"displayName":"Navami Sunil Rajagiri","userId":"01137070985807425093"},"user_tz":-330},"id":"Av2DpIxypPaI","outputId":"4a5286b8-d12e-4d8e-da00-a9a7ca4e86a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 128)               45568     \n","                                                                 \n"," dropout (Dropout)           (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dropout_1 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 129)               8385      \n","                                                                 \n","=================================================================\n","Total params: 62209 (243.00 KB)\n","Trainable params: 62209 (243.00 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 128)               45568     \n","                                                                 \n"," dropout (Dropout)           (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dropout_1 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 129)               8385      \n","                                                                 \n","=================================================================\n","Total params: 62209 (243.00 KB)\n","Trainable params: 62209 (243.00 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n"]}],"source":["print(model.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZaAiSrSsJ1pg"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":437},"executionInfo":{"elapsed":139,"status":"error","timestamp":1707734004107,"user":{"displayName":"Navami Sunil Rajagiri","userId":"01137070985807425093"},"user_tz":-330},"id":"owVAXSLrpNdR","outputId":"7424a367-7c52-4e6e-ff41-1bdca4cfd487"},"outputs":[{"ename":"NameError","evalue":"name 'test_dataset' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-fe56afdea52c>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Assuming test_dataset contains test queries with corresponding intents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# and predicted_intents contains the intents predicted by the chatbot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_intents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"]},{"ename":"NameError","evalue":"name 'test_dataset' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-fe56afdea52c>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Assuming test_dataset contains test queries with corresponding intents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# and predicted_intents contains the intents predicted by the chatbot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_intents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"]}],"source":["def calculate_precision(test_dataset, predicted_intents):\n","    correct_predictions = 0\n","    total_predictions = len(predicted_intents)\n","\n","    for i in range(total_predictions):\n","        if predicted_intents[i] == test_dataset[i]['intent']:\n","            correct_predictions += 1\n","\n","    precision = correct_predictions / total_predictions\n","    return precision\n","\n","# Assuming test_dataset contains test queries with corresponding intents\n","# and predicted_intents contains the intents predicted by the chatbot\n","precision = calculate_precision(test_dataset, predicted_intents)\n","print(\"Precision:\", precision)\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"1K5f3xlDSlhp"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading collection 'popular'\n","[nltk_data]    | \n","[nltk_data]    | Downloading package cmudict to\n","[nltk_data]    |     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpopular\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#  Natural Language Toolkit (NLTK) library installed will download and\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# install a collection of popular NLTK data packages, including corpora,\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# models etc\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstem\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordNetLemmatizer\n","File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\downloader.py:777\u001b[0m, in \u001b[0;36mDownloader.download\u001b[1;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error, print_error_to)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(s, prefix2\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    769\u001b[0m     print_to(\n\u001b[0;32m    770\u001b[0m         textwrap\u001b[38;5;241m.\u001b[39mfill(\n\u001b[0;32m    771\u001b[0m             s,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    774\u001b[0m         )\n\u001b[0;32m    775\u001b[0m     )\n\u001b[1;32m--> 777\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincr_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo_or_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Error messages\u001b[39;49;00m\n\u001b[0;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mErrorMessage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\downloader.py:637\u001b[0m, in \u001b[0;36mDownloader.incr_download\u001b[1;34m(self, info_or_id, download_dir, force)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(info, Collection):\n\u001b[0;32m    636\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m StartCollectionMessage(info)\n\u001b[1;32m--> 637\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mincr_download(info\u001b[38;5;241m.\u001b[39mchildren, download_dir, force)\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m FinishCollectionMessage(info)\n\u001b[0;32m    640\u001b[0m \u001b[38;5;66;03m# Handle Packages (delegate to a helper function).\u001b[39;00m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\downloader.py:624\u001b[0m, in \u001b[0;36mDownloader.incr_download\u001b[1;34m(self, info_or_id, download_dir, force)\u001b[0m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;66;03m# If they gave us a list of ids, then download each one.\u001b[39;00m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(info_or_id, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 624\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_list(info_or_id, download_dir, force)\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;66;03m# Look up the requested collection or package.\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\downloader.py:667\u001b[0m, in \u001b[0;36mDownloader._download_list\u001b[1;34m(self, items, download_dir, force)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    666\u001b[0m     delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(item\u001b[38;5;241m.\u001b[39mpackages) \u001b[38;5;241m/\u001b[39m num_packages\n\u001b[1;32m--> 667\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincr_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mProgressMessage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mProgressMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\downloader.py:642\u001b[0m, in \u001b[0;36mDownloader.incr_download\u001b[1;34m(self, info_or_id, download_dir, force)\u001b[0m\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m FinishCollectionMessage(info)\n\u001b[0;32m    640\u001b[0m \u001b[38;5;66;03m# Handle Packages (delegate to a helper function).\u001b[39;00m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 642\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_package(info, download_dir, force)\n","File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\downloader.py:712\u001b[0m, in \u001b[0;36mDownloader._download_package\u001b[1;34m(self, info, download_dir, force)\u001b[0m\n\u001b[0;32m    710\u001b[0m num_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, info\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m16\u001b[39m))\n\u001b[0;32m    711\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mcount():\n\u001b[1;32m--> 712\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43minfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 16k blocks.\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     outfile\u001b[38;5;241m.\u001b[39mwrite(s)\n\u001b[0;32m    714\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s:\n","File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:473\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    472\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 473\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n","File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n","File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import nltk\n","nltk.download('popular')#  Natural Language Toolkit (NLTK) library installed will download and\n","# install a collection of popular NLTK data packages, including corpora,\n","# models etc\n","from nltk.stem import WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()\n","import pickle\n","import numpy as np\n","from keras.models import load_model\n","model = load_model('/content/drive/MyDrive/Decobot/model.h5')\n","import json\n","import random\n","\n","\n","\n","\n","from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n","import spacy\n","from spacy.language import Language\n","from spacy_langdetect import LanguageDetector\n","\n","\n","# translator pipeline for english to swahili translations\n","# eng_swa_model_checkpoint = \"Helsinki-NLP/opus-mt-en-swc\"\n","# eng_swa_tokenizer = AutoTokenizer.from_pretrained(\"./model/en_sw/\")\n","# eng_swa_model = AutoModelForSeq2SeqLM.from_pretrained(\"./model/en_sw/\")\n","\n","# eng_swa_translator = pipeline(\n","#     \"text2text-generation\",\n","#     model=eng_swa_model,\n","#     tokenizer=eng_swa_tokenizer,\n","# )\n","\n","# def translate_text_eng_swa(text):\n","#     translated_text = eng_swa_translator(text, max_length=128, num_beams=5)[0]['generated_text']\n","#     return translated_text\n","\n","# translator pipeline for swahili to english translations\n","# swa_eng_model_checkpoint = \"Helsinki-NLP/opus-mt-swc-en\"\n","# swa_eng_tokenizer = AutoTokenizer.from_pretrained(\"./model/sw_en/\")\n","# swa_eng_model = AutoModelForSeq2SeqLM.from_pretrained(\"./model/sw_en/\")\n","\n","# swa_eng_translator = pipeline(\n","#     \"text2text-generation\",\n","#     model=swa_eng_model,\n","#     tokenizer=swa_eng_tokenizer,\n","# )\n","\n","# def translate_text_swa_eng(text):\n","#     translated_text = swa_eng_translator(text, max_length=128, num_beams=5)[0]['generated_text']\n","#     return translated_text\n","\n","\n","# # Language detector\n","# def get_lang_detector(nlp, name):\n","#     return LanguageDetector()\n","\n","# # # Load the English language model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# # Register the language detection factory\n","# Language.factory(\"language_detector\", func=get_lang_detector)\n","\n","# # # Add the language detection component to the pipeline\n","# nlp.add_pipe('language_detector', last=True)\n","\n","\n","\n","\n","\n","intents = json.loads(open('intents.json').read())\n","words = pickle.load(open('texts.pkl','rb'))\n","classes = pickle.load(open('labels.pkl','rb'))\n","def clean_up_sentence(sentence):\n","    # tokenize the pattern - split words into array\n","    sentence_words = nltk.word_tokenize(sentence)\n","    # stem each word - create short form for word\n","    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n","    return sentence_words\n","# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n","def bow(sentence, words, show_details=True):\n","    # tokenize the pattern\n","    sentence_words = clean_up_sentence(sentence)\n","    # bag of words - matrix of N words, vocabulary matrix\n","    bag = [0]*len(words)\n","    for s in sentence_words:\n","        for i,w in enumerate(words):\n","            if w == s:\n","                # assign 1 if current word is in the vocabulary position\n","                bag[i] = 1\n","                if show_details:\n","                    print (\"found in bag: %s\" % w)\n","    return(np.array(bag))\n","def predict_class(sentence, model):\n","    # filter out predictions below a threshold\n","    p = bow(sentence, words,show_details=False)\n","    res = model.predict(np.array([p]))[0]\n","    ERROR_THRESHOLD = 0.25\n","    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n","    # sort by strength of probability\n","    results.sort(key=lambda x: x[1], reverse=True)\n","    return_list = []\n","    for r in results:\n","        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n","    return return_list\n","\n","def getResponse(ints, intents_json):\n","    if ints:\n","        tag = ints[0]['intent']\n","        list_of_intents = intents_json['intents']\n","        for i in list_of_intents:\n","            if i['tag'] == tag:\n","                result = random.choice(i['responses'])\n","                break\n","        return result\n","    else:\n","        return \"Sorry, I didn't understand that.\"\n","\n","def chatbot_response(msg):\n","    ints = predict_class(msg, model)\n","    res = getResponse(ints, intents)\n","    print(res)\n","\n","    # # language detection\n","    # doc = nlp(res)\n","    # detected_language = doc._.language['language']\n","    # print(f\"Detected language: {detected_language}\")\n","\n","    # translated_response = res\n","\n","    # if detected_language == \"en\":\n","    #     pass\n","    # elif detected_language == 'sw':\n","    #     translated_response = translate_text_eng_swa(res)\n","\n","    # print(translated_response)\n","    # return translated_response\n","\n","# Creating GUI with flask\n","from flask import Flask, render_template, request\n","app = Flask(__name__,template_folder='/content/drive/MyDrive/Decobot/templates')\n","app.static_folder = 'static'\n","@app.route(\"/\")\n","def home():\n","    return render_template(\"index.html\")\n","@app.route(\"/get\")\n","def get_bot_response():\n","    userText = request.args.get('msg')\n","    print(userText)\n","\n","    # language detection\n","    # doc = nlp(userText)\n","    # detected_language = doc._.language['language']\n","    # print(f\"Detected language: {detected_language}\")\n","\n","    # if detected_language == \"en\":\n","    response = chatbot_response(userText)\n","    # elif detected_language == 'sw':\n","    #     response = translate_text_eng_swa(chatbot_response(userText))\n","\n","    print(response)\n","    return response\n","if __name__ == \"__main__\":\n","    app.run()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N1fpzTGrKwZ7"},"outputs":[],"source":["import json\n","import random\n","\n","# Load the JSON dataset\n","with open('intents.json', 'r') as file:\n","    dataset = json.load(file)\n","\n","# Convert the dictionary to a list of tuples (query, intent)\n","dataset_list = [(sample['query'], sample['intent']) for sample in dataset]\n","\n","# Shuffle the dataset\n","random.shuffle(dataset_list)\n","\n","# Define the ratio for splitting the dataset\n","train_ratio = 0.8  # 80% for training, 20% for testing\n","\n","# Split the dataset into training and testing parts\n","train_size = int(len(dataset_list) * train_ratio)\n","train_dataset = dataset_list[:train_size]\n","test_dataset = dataset_list[train_size:]\n","\n","# Save or use the training and testing datasets as needed\n","# For example:\n","with open('train_dataset.json', 'w') as file:\n","    json.dump(train_dataset, file)\n","\n","with open('test_dataset.json', 'w') as file:\n","    json.dump(test_dataset, file)\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}
